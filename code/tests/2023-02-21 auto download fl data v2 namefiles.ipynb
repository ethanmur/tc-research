{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb8fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## end of 2/21/2023 update:\n",
    "## This notebook builds upon the V1 code by synthesizing steps to automatically download data!\n",
    "## It can load data from all years / TC names, or just specified cases\n",
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9588fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import...\n",
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import xarray as xr\n",
    "\n",
    "os.chdir( \"/Users/etmu9498/research/code/scripts/plotting\")\n",
    "import auto_flight_level_plots_new_noaa_data as plotter\n",
    "import fl_mean_plots_error\n",
    "import fl_mean_fields_binned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd23651e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019', '2020']\n"
     ]
    }
   ],
   "source": [
    "# step 1: save all years included in noaa's flight level database to yearfiles\n",
    "\n",
    "# get a string holding all the folder names\n",
    "urlrootstr = 'https://www.aoml.noaa.gov/ftp/hrd/data/flightlevel/'\n",
    "urlrootpath =urlopen( urlrootstr)\n",
    "string = urlrootpath.read().decode('utf-8')\n",
    "\n",
    "# separate the one long string into a list of year strings\n",
    "stringlist = string.split(\"</li>\")\n",
    "stringlist = stringlist[ 1:-1] # get rid of meaningless header and footer\n",
    "\n",
    "\n",
    "# define a pattern of files to sort for\n",
    "# this looks for files with the header '<li><a href=\", with 4 numbers (representing a year), with the footer /\">\n",
    "pattern = re.compile('<li><a href=\"[0-9]{4}/\">') # only look in folders with year numbers\n",
    "\n",
    "# save valid years here\n",
    "yearfiles = []\n",
    "# sort for the intended files and print out valid years!\n",
    "# look through all potential year strings\n",
    "for i, val in enumerate( stringlist):\n",
    "       \n",
    "    # add this case if it passes the pattern test above!\n",
    "    if re.search( pattern, val):\n",
    "        match = re.search( pattern, val)\n",
    "        name = val [ 14 : 18 ]\n",
    "        \n",
    "        yearfiles.append( name)\n",
    "\n",
    "\n",
    "# option 2: manually set the year list (better for faster downloads and testing)\n",
    "yearfiles = [ '2019' , '2020']\n",
    "\n",
    "print( yearfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0654498d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2019 complete\n",
      "Year 2020 complete\n"
     ]
    }
   ],
   "source": [
    "# step 2: find the unique tc names for each year\n",
    "\n",
    "# make sure there's an empty list for every year! names will be added for each year\n",
    "namefiles = []\n",
    "for i in range( len( yearfiles)):\n",
    "    namefiles.append( [])\n",
    "\n",
    "\n",
    "# do this for every year\n",
    "for yeari, yearval in enumerate( yearfiles):\n",
    "\n",
    "    # go to the current year's folder on NOAA's website\n",
    "    yearstr = 'https://www.aoml.noaa.gov/ftp/hrd/data/flightlevel/' + yearval\n",
    "    yearpath =urlopen( yearstr)\n",
    "    string = yearpath.read().decode('utf-8')\n",
    "\n",
    "    # separate the one long string into a list of name strings\n",
    "    stringlist = string.split(\"</li>\")\n",
    "    stringlist = stringlist[ 1:-1] # get rid of meaningless header and footer\n",
    "    \n",
    "    # define a pattern of files to sort for\n",
    "    # this code looks for files with the header '<li><a href=\", with any number of letters (representing a name), \n",
    "    # with the footer /\">\n",
    "    pattern = re.compile('<li><a href=\"[a-zA-Z]*/\">') # only look in folders with year numbers\n",
    "\n",
    "    # look through all potential name strings\n",
    "    for i, val in enumerate( stringlist):\n",
    "\n",
    "        # add this case if it passes the pattern test above!\n",
    "        if re.search( pattern, val):\n",
    "\n",
    "            # trim off name header\n",
    "            name = val [ 14:]            \n",
    "            # find the first /, signifying the end of the name\n",
    "            for j in range( len( name)):\n",
    "                if name[ j] == '/':\n",
    "                    endval = j\n",
    "                    break\n",
    "            # trim off the footer and append the name!        \n",
    "            name = name [ : endval]\n",
    "            namefiles[ yeari].append( name)\n",
    "\n",
    "    print( \"Year \" + yearval + \" complete\")\n",
    "\n",
    "# option 2: input the TC names manually! to save on data downloading times\n",
    "\n",
    "namefiles[ 0] = ['lorenzo'] # ['dorian', 'lorenzo'] # 2019 names\n",
    "namefiles[ 1] = [] # ['delta', 'isaias', 'zeta'] # 2020 names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "961a7e59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2019\n",
      "Names: ['lorenzo']\n",
      "Year: 2020\n",
      "Names: []\n"
     ]
    }
   ],
   "source": [
    "# print out the years / names nicely!\n",
    "for yeari, yearval in enumerate( yearfiles):\n",
    "    print( \"Year: \" + yearval)\n",
    "    print( \"Names: \" + str( namefiles[ yeari]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88e21263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get filenames for 2019\n",
      "TC lorenzo\n",
      "Get filenames for 2020\n"
     ]
    }
   ],
   "source": [
    "# step 3: get filenames\n",
    "\n",
    "# save new valid filenames here\n",
    "files = []\n",
    "# make sure there's an empty list for every year! dataset names from all that year's TCs will be \n",
    "# placed in the appropriate list\n",
    "for i in range( len( yearfiles)):\n",
    "        \n",
    "    files.append( [])\n",
    "    \n",
    "    for j  in range( len( namefiles[ i])):\n",
    "        files[i].append( [])\n",
    "        \n",
    "# do this for each year and each name\n",
    "for yeari, yearval in enumerate( yearfiles):\n",
    "\n",
    "    print( \"Get filenames for \" + yearval)\n",
    "    \n",
    "    for namei, nameval in enumerate( namefiles[ yeari]):\n",
    "        \n",
    "        print( \"TC \" + nameval)\n",
    "        \n",
    "        # go to this TC's link\n",
    "        urlstr = 'https://www.aoml.noaa.gov/ftp/hrd/data/flightlevel/' + yearval + '/' + nameval + '/'\n",
    "        urlpath =urlopen( urlstr)\n",
    "        string = urlpath.read().decode('utf-8')\n",
    "\n",
    "\n",
    "        # break down the one huge string into a list of strings.\n",
    "        # separate them by the </li> character\n",
    "        # cut the first and last entries off the list -> not filenames!\n",
    "        stringlist = string.split(\"</li>\")\n",
    "        stringlist = stringlist[ 1:-1] # get rid of meaningless header and footer\n",
    "\n",
    "        # define a pattern of files to sort for\n",
    "        # pattern = re.compile('<li><a href=\".*_AC.nc\">') # include any _AC.nc file (H, I, or N)\n",
    "        pattern = re.compile('<li><a href=\".*[HI][12]_AC.nc\">.*') # only save H or I files, not N\n",
    "\n",
    "\n",
    "        # sort for the intended files and save valid names!\n",
    "        for i, val in enumerate( stringlist):\n",
    "\n",
    "            if re.search( pattern, val):\n",
    "                name = val[ 14 : 30 ]\n",
    "                files[yeari][namei] .append( name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3404cd84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files for year 2019, TC lorenzo:\n",
      "['20190926I1_AC.nc', '20190927H1_AC.nc', '20190927I1_AC.nc', '20190928H1_AC.nc', '20190928I1_AC.nc', '20190929H1_AC.nc', '20190929I1_AC.nc', '20190930H1_AC.nc', '20190930I1_AC.nc']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print filenames nicely!\n",
    "for yeari, yearval in enumerate( yearfiles):\n",
    "    for namei, nameval in enumerate( namefiles[ yeari]):\n",
    "        print( \"Files for year \" + yearval + \", TC \" + str( namefiles[ yeari][namei]) + \":\")\n",
    "        print( str( files[ yeari][namei] ) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bd67e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of netCDF datasets to download: 9\n",
      "Saving data for TC lorenzo\n",
      "20190926I1_lorenzo.nc\n",
      "file 0 downloaded\n",
      "20190927H1_lorenzo.nc\n",
      "file 1 downloaded\n",
      "20190927I1_lorenzo.nc\n",
      "file 2 downloaded\n",
      "20190928H1_lorenzo.nc\n",
      "file 3 downloaded\n",
      "20190928I1_lorenzo.nc\n",
      "file 4 downloaded\n",
      "20190929H1_lorenzo.nc\n",
      "file 5 downloaded\n",
      "20190929I1_lorenzo.nc\n",
      "file 6 downloaded\n",
      "20190930H1_lorenzo.nc\n",
      "file 7 downloaded\n",
      "20190930I1_lorenzo.nc\n",
      "file 8 downloaded\n"
     ]
    }
   ],
   "source": [
    "# step 4: download the files printed out above!\n",
    "###########\n",
    "# new code: save files in separate year AND tcname files!\n",
    "# this will make things much more readable when working with 100+ cases\n",
    "# it also matches NOAA's file structure better, which is probably a good thing!\n",
    "# it will also make metadata matching easier! no overlapping dates, etc\n",
    "###########\n",
    "\n",
    "\n",
    "total_file_count = 0 \n",
    "for yeari, yearval in enumerate( yearfiles):\n",
    "    for namei, nameval in enumerate( namefiles[ yeari]):\n",
    "        total_file_count += len( files[ yeari][ namei])\n",
    "print( \"Number of netCDF datasets to download: \" + str( total_file_count))\n",
    "\n",
    "\n",
    "# do this for each year and each name\n",
    "for yeari, yearval in enumerate( yearfiles):\n",
    "\n",
    "    for namei, nameval in enumerate( namefiles[ yeari]):\n",
    "        print( \"Saving data for TC \" + nameval)\n",
    "\n",
    "        # see if there's already a year folder availible\n",
    "        os.chdir(\"/Users/etmu9498/research/data/in-situ-noaa-full\")\n",
    "        output_folder = yearval + \"/\" + nameval\n",
    "\n",
    "        if not os.path.isdir( output_folder):\n",
    "            os.makedirs( output_folder)\n",
    "            print( 'New folder created: ' + output_folder)\n",
    "        \n",
    "        # go to the new folder\n",
    "        os.chdir(\"/Users/etmu9498/research/data/in-situ-noaa-full/\" + output_folder)\n",
    "\n",
    "        # save the valid datasets!\n",
    "        for i, val in enumerate( files[yeari][namei]):\n",
    "            \n",
    "            # urllib.request.urlretrieve( urlstr + val, val)\n",
    "            # print( val[0:10] + \"_\" + nameval + \".nc\")\n",
    "            print( \"file \" + str( i) + \" downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43d6190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that downloads look good!\n",
    "os.chdir(\"/Users/etmu9498/research/data/in-situ-noaa-full/2019\" )\n",
    "data = xr.open_dataset( '20190919H1_AC.nc', decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c0f26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "494e0003",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019', '2020', '2021', '2022']\n",
      "['jerry', 'lorenzo']\n",
      "['laura', 'sally', 'teddy']\n",
      "['ida', 'larry', 'sam']\n",
      "['fiona']\n",
      "52\n",
      "Total Number of plots to be created: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "## code taken from \"2023-02-01 flight level rmws new nc datasets\"\n",
    "## results: the auto code works really well on the automatically downloaded data!\n",
    "#################\n",
    "\n",
    "import os\n",
    "os.chdir( \"/Users/etmu9498/research/code/scripts/plotting\")\n",
    "import auto_flight_level_plots_new_noaa_data as plotter\n",
    "\n",
    "\n",
    "plotter.plot( tc='2019', ylims=True, filepaths='New')\n",
    "#fl_mean_fields_binned.plot_all_eyes( tc='2019', max_v_requirement=40, filepaths='New')\n",
    "#fl_mean_plots_error.make_plot( tc='2019', max_v_requirement=40, filepaths='New')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7259a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## 2/22/23 update\n",
    "## testing new code with updated file structures! a little more complicated because of all the subfolders\n",
    "###############\n",
    "#import os\n",
    "#os.chdir( \"/Users/etmu9498/research/code/scripts-winter2023/fl-data-compositing\")\n",
    "#import fl_time_series_new_noaa_data\n",
    "#fl_time_series_new_noaa_data.plot( tc='all', ylims=True, filepaths='New')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f341b712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
