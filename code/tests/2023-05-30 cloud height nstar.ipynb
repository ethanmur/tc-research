{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d694ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal #for signal processing\n",
    "import scipy.stats as stats\n",
    "\n",
    "os.chdir(\"/Users/etmu9498/research/code/scripts-winter2023/\")\n",
    "import helper_fns_winter2023\n",
    "sys.path.append(  \"/Users/etmu9498/research/code/scripts-winter2023/cloud-top-height-stats\")\n",
    "import eyewall_metadata\n",
    "import find_cloud_tops\n",
    "import cloud_top_plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006bf5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper fns\n",
    "\n",
    "# get the power spectrum of red noise for this dataset\n",
    "def create_normalized_redfit(data_length,Te):\n",
    "    freq = np.arange(0,(data_length/2)+1,1)/float(data_length) # to Nyquist\n",
    "    red_fit = (2 * Te)/(1 + ((2*np.pi*freq)**2)*(Te**2)) # After Hartmann 6.64, 6.91\n",
    "    return red_fit/np.sum(red_fit)\n",
    "\n",
    "# using the red noise power spectrum and a given confidence level, calculate the confidence limits for each data point\n",
    "def create_f_bounds(alpha,dof,red_fit_n):\n",
    "    f_ratio = stats.f.ppf(alpha,dof,200) # Note: 200 = large degree of freedom for red noise\n",
    "    return f_ratio*red_fit_n\n",
    "\n",
    "def eyewall_finder_helper(yearval, date, metadata):\n",
    "    # check if this date exists... if not, give it some empty eyewall limits!\n",
    "    # also account for fred am and pm cases!!\n",
    "    if date == '0812':\n",
    "        if fileval[11:13] == \"H1\":\n",
    "            eyewall_limits = metadata[ yearval]['eyewall_limits'][ '0812am']\n",
    "        elif fileval[11:13] == \"H2\":\n",
    "            eyewall_limits = metadata[ yearval]['eyewall_limits'][ '0812pm']\n",
    "    elif date in metadata[ yearval]['eyewall_limits'].keys():\n",
    "        eyewall_limits = metadata[ yearval]['eyewall_limits'][ date]\n",
    "    else:\n",
    "        eyewall_limits = [ ()]\n",
    "\n",
    "    return eyewall_limits\n",
    "\n",
    "#Method #1\n",
    "#Calculate the autocorrelation using numpy correlate lagN\n",
    "def method1( t1_m, t2_m, N, lag, sigma):\n",
    "    return np.correlate( t1_m, t2_m, mode='valid')/( N - lag)/( sigma**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a68bc03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data files to be used in analysis: 35\n",
      "Year: 2021\n",
      "File: P3_20210811H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "File: P3_20210812H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 343\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.77271\n",
      "Effective Sample Size Wilks N* (#independent samples): 44.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.77 and Te = 4.0\n",
      "Window = 285.83333333333337\n",
      "DOF = 2.3999999999999995\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 218\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.93583\n",
      "Effective Sample Size Wilks N* (#independent samples): 7.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.94 and Te = 16.0\n",
      "Window = 181.66666666666669\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 378\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.98347\n",
      "Effective Sample Size Wilks N* (#independent samples): 3.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.99 and Te = 110.0\n",
      "Window = 315.0\n",
      "DOF = 2.4\n",
      "File: P3_20210812H2_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 374\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.76412\n",
      "Effective Sample Size Wilks N* (#independent samples): 50.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.76 and Te = 4.0\n",
      "Window = 311.6666666666667\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 368\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.926\n",
      "Effective Sample Size Wilks N* (#independent samples): 14.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.93 and Te = 14.0\n",
      "Window = 306.6666666666667\n",
      "DOF = 2.4\n",
      "File: P3_20210813H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 125\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.63708\n",
      "Effective Sample Size Wilks N* (#independent samples): 28.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.65 and Te = 2.0\n",
      "Window = 104.16666666666667\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 371\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.8972\n",
      "Effective Sample Size Wilks N* (#independent samples): 20.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.9 and Te = 10.0\n",
      "Window = 309.1666666666667\n",
      "DOF = 2.4\n",
      "File: P3_20210816H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 385\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.94698\n",
      "Effective Sample Size Wilks N* (#independent samples): 10.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.95 and Te = 19.0\n",
      "Window = 320.83333333333337\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 323\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.78085\n",
      "Effective Sample Size Wilks N* (#independent samples): 40.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.78 and Te = 4.0\n",
      "Window = 269.1666666666667\n",
      "DOF = 2.4\n",
      "File: P3_20210817H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 510\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.86437\n",
      "Effective Sample Size Wilks N* (#independent samples): 37.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.87 and Te = 7.0\n",
      "Window = 425.0\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 350\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.90551\n",
      "Effective Sample Size Wilks N* (#independent samples): 17.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.91 and Te = 10.0\n",
      "Window = 291.6666666666667\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 377\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.92824\n",
      "Effective Sample Size Wilks N* (#independent samples): 14.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.93 and Te = 13.0\n",
      "Window = 314.1666666666667\n",
      "DOF = 2.4\n",
      "File: P3_20210818H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 99\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.88733\n",
      "Effective Sample Size Wilks N* (#independent samples): 6.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.88 and Te = 8.0\n",
      "Window = 82.5\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 160\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.81166\n",
      "Effective Sample Size Wilks N* (#independent samples): 17.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.81 and Te = 5.0\n",
      "Window = 133.33333333333334\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 130\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.74436\n",
      "Effective Sample Size Wilks N* (#independent samples): 19.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.75 and Te = 3.0\n",
      "Window = 108.33333333333334\n",
      "DOF = 2.4\n",
      "File: P3_20210819H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 162\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.84202\n",
      "Effective Sample Size Wilks N* (#independent samples): 14.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.84 and Te = 6.0\n",
      "Window = 135.0\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 225\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.90701\n",
      "Effective Sample Size Wilks N* (#independent samples): 11.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.91 and Te = 10.0\n",
      "Window = 187.5\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 305\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.84043\n",
      "Effective Sample Size Wilks N* (#independent samples): 26.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.84 and Te = 6.0\n",
      "Window = 254.16666666666669\n",
      "DOF = 2.4\n",
      "File: P3_20210820H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 404\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.9476\n",
      "Effective Sample Size Wilks N* (#independent samples): 11.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.95 and Te = 19.0\n",
      "Window = 336.6666666666667\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 404\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.87628\n",
      "Effective Sample Size Wilks N* (#independent samples): 27.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.89 and Te = 9.0\n",
      "Window = 336.6666666666667\n",
      "DOF = 2.4\n",
      "File: P3_20210821H2_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 145\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.72008\n",
      "Effective Sample Size Wilks N* (#independent samples): 24.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.72 and Te = 3.0\n",
      "Window = 120.83333333333334\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 129\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.75916\n",
      "Effective Sample Size Wilks N* (#independent samples): 18.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.76 and Te = 4.0\n",
      "Window = 107.5\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 179\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.8379\n",
      "Effective Sample Size Wilks N* (#independent samples): 16.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.84 and Te = 6.0\n",
      "Window = 149.16666666666669\n",
      "DOF = 2.4\n",
      "File: P3_20210827H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 269\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.64121\n",
      "Effective Sample Size Wilks N* (#independent samples): 59.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.64 and Te = 2.0\n",
      "Window = 224.16666666666669\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 196\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.83447\n",
      "Effective Sample Size Wilks N* (#independent samples): 18.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.83 and Te = 5.0\n",
      "Window = 163.33333333333334\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 99\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.68189\n",
      "Effective Sample Size Wilks N* (#independent samples): 19.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.68 and Te = 3.0\n",
      "Window = 82.5\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 3\n",
      "Number of Heights = 207\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.82995\n",
      "Effective Sample Size Wilks N* (#independent samples): 19.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.84 and Te = 6.0\n",
      "Window = 172.5\n",
      "DOF = 2.4\n",
      "File: P3_20210828H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 180\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.7945\n",
      "Effective Sample Size Wilks N* (#independent samples): 21.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.8 and Te = 4.0\n",
      "Window = 150.0\n",
      "DOF = 2.4\n",
      "File: P3_20210829H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 68\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.83513\n",
      "Effective Sample Size Wilks N* (#independent samples): 6.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.84 and Te = 6.0\n",
      "Window = 56.66666666666667\n",
      "DOF = 2.4\n",
      "File: P3_20210925H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "File: P3_20210926H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 184\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.7854\n",
      "Effective Sample Size Wilks N* (#independent samples): 22.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.78 and Te = 4.0\n",
      "Window = 153.33333333333334\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 88\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.93731\n",
      "Effective Sample Size Wilks N* (#independent samples): 3.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.95 and Te = 18.0\n",
      "Window = 73.33333333333334\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Heights = 129\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.60959\n",
      "Effective Sample Size Wilks N* (#independent samples): 31.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.61 and Te = 2.0\n",
      "Window = 107.5\n",
      "DOF = 2.4\n",
      "File: P3_20210927H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 118\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.94182\n",
      "Effective Sample Size Wilks N* (#independent samples): 4.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.94 and Te = 16.0\n",
      "Window = 98.33333333333334\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 77\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.94827\n",
      "Effective Sample Size Wilks N* (#independent samples): 2.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.94 and Te = 15.0\n",
      "Window = 64.16666666666667\n",
      "DOF = 2.4\n",
      "File: P3_20210929H2_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 181\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.88949\n",
      "Effective Sample Size Wilks N* (#independent samples): 11.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.89 and Te = 9.0\n",
      "Window = 150.83333333333334\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 160\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.76776\n",
      "Effective Sample Size Wilks N* (#independent samples): 21.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.77 and Te = 4.0\n",
      "Window = 133.33333333333334\n",
      "DOF = 2.4\n",
      "Year: 2022\n",
      "File: P3_20220830H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "File: P3_20220831H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "File: P3_20220901H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 75\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.7931\n",
      "Effective Sample Size Wilks N* (#independent samples): 9.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.8 and Te = 5.0\n",
      "Window = 62.5\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 72\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.78023\n",
      "Effective Sample Size Wilks N* (#independent samples): 9.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.79 and Te = 4.0\n",
      "Window = 60.0\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 83\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.8001\n",
      "Effective Sample Size Wilks N* (#independent samples): 9.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.86 and Te = 6.0\n",
      "Window = 69.16666666666667\n",
      "DOF = 2.4\n",
      "File: P3_20220903H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 91\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.65065\n",
      "Effective Sample Size Wilks N* (#independent samples): 19.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.66 and Te = 2.0\n",
      "Window = 75.83333333333334\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 76\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.51776\n",
      "Effective Sample Size Wilks N* (#independent samples): 24.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.51 and Te = 2.0\n",
      "Window = 63.333333333333336\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 81\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.55368\n",
      "Effective Sample Size Wilks N* (#independent samples): 23.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.56 and Te = 2.0\n",
      "Window = 67.5\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 3\n",
      "Number of Heights = 77\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.79184\n",
      "Effective Sample Size Wilks N* (#independent samples): 9.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.81 and Te = 5.0\n",
      "Window = 64.16666666666667\n",
      "DOF = 2.4\n",
      "File: P3_20220904H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 84\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.77574\n",
      "Effective Sample Size Wilks N* (#independent samples): 11.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.79 and Te = 4.0\n",
      "Window = 70.0\n",
      "DOF = 2.4\n",
      "File: P3_20220905H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 96\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.80232\n",
      "Effective Sample Size Wilks N* (#independent samples): 11.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.8 and Te = 5.0\n",
      "Window = 80.0\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 76\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.76562\n",
      "Effective Sample Size Wilks N* (#independent samples): 10.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.76 and Te = 4.0\n",
      "Window = 63.333333333333336\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 54\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.59377\n",
      "Effective Sample Size Wilks N* (#independent samples): 14.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.59 and Te = 2.0\n",
      "Window = 45.0\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 3\n",
      "Number of Heights = 79\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.82137\n",
      "Effective Sample Size Wilks N* (#independent samples): 8.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.83 and Te = 5.0\n",
      "Window = 65.83333333333334\n",
      "DOF = 2.3999999999999995\n",
      "File: P3_20220906H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 73\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.56075\n",
      "Effective Sample Size Wilks N* (#independent samples): 21.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.56 and Te = 2.0\n",
      "Window = 60.833333333333336\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 91\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.52514\n",
      "Effective Sample Size Wilks N* (#independent samples): 28.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.52 and Te = 2.0\n",
      "Window = 75.83333333333334\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 78\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.75768\n",
      "Effective Sample Size Wilks N* (#independent samples): 11.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.76 and Te = 4.0\n",
      "Window = 65.0\n",
      "DOF = 2.4\n",
      "File: P3_20220908H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 252\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.71678\n",
      "Effective Sample Size Wilks N* (#independent samples): 42.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.72 and Te = 3.0\n",
      "Window = 210.0\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 288\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.75171\n",
      "Effective Sample Size Wilks N* (#independent samples): 41.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.75 and Te = 3.0\n",
      "Window = 240.0\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 162\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.6863\n",
      "Effective Sample Size Wilks N* (#independent samples): 30.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.68 and Te = 3.0\n",
      "Window = 135.0\n",
      "DOF = 2.4\n",
      "File: P3_20220916H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 81\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.68811\n",
      "Effective Sample Size Wilks N* (#independent samples): 15.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.69 and Te = 3.0\n",
      "Window = 67.5\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 77\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.80349\n",
      "Effective Sample Size Wilks N* (#independent samples): 8.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.8 and Te = 4.0\n",
      "Window = 64.16666666666667\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 86\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.48134\n",
      "Effective Sample Size Wilks N* (#independent samples): 30.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.48 and Te = 1.0\n",
      "Window = 71.66666666666667\n",
      "DOF = 2.4\n",
      "File: P3_20220917H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 73\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.75387\n",
      "Effective Sample Size Wilks N* (#independent samples): 10.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.75 and Te = 4.0\n",
      "Window = 60.833333333333336\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 86\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.69606\n",
      "Effective Sample Size Wilks N* (#independent samples): 15.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.7 and Te = 3.0\n",
      "Window = 71.66666666666667\n",
      "DOF = 2.4\n",
      "File: P3_20220918H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 22\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.33644\n",
      "Effective Sample Size Wilks N* (#independent samples): 11.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.4 and Te = 1.0\n",
      "Window = 18.333333333333336\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 26\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.34724\n",
      "Effective Sample Size Wilks N* (#independent samples): 13.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.38 and Te = 1.0\n",
      "Window = 21.666666666666668\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 55\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.46768\n",
      "Effective Sample Size Wilks N* (#independent samples): 20.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.47 and Te = 1.0\n",
      "Window = 45.833333333333336\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Heights = 102\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.60696\n",
      "Effective Sample Size Wilks N* (#independent samples): 25.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.61 and Te = 2.0\n",
      "Window = 85.0\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 4\n",
      "Number of Heights = 58\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.69247\n",
      "Effective Sample Size Wilks N* (#independent samples): 11.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.68 and Te = 3.0\n",
      "Window = 48.333333333333336\n",
      "DOF = 2.4\n",
      "File: P3_20220920H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 36\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.86644\n",
      "Effective Sample Size Wilks N* (#independent samples): 3.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.84 and Te = 6.0\n",
      "Window = 30.0\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 14\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.75988\n",
      "Effective Sample Size Wilks N* (#independent samples): 2.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.78 and Te = 4.0\n",
      "Window = 11.666666666666668\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 15\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: -0.12488\n",
      "Effective Sample Size Wilks N* (#independent samples): 19.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = -0.12 and Te = nan\n",
      "Window = 12.5\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 3\n",
      "Number of Heights = 30\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.83563\n",
      "Effective Sample Size Wilks N* (#independent samples): 3.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.81 and Te = 5.0\n",
      "Window = 25.0\n",
      "DOF = 2.4\n",
      "File: P3_20220924H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 115\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.92306\n",
      "Effective Sample Size Wilks N* (#independent samples): 5.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.92 and Te = 12.0\n",
      "Window = 95.83333333333334\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 72\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.61052\n",
      "Effective Sample Size Wilks N* (#independent samples): 17.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.6 and Te = 2.0\n",
      "Window = 60.0\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etmu9498\\AppData\\Local\\Temp\\ipykernel_24428\\1532473198.py:90: RuntimeWarning: invalid value encountered in log\n",
      "  Nstar_leith= np.round((-0.5*np.log(xAR1))*xN) ## Barnes Chapter 2 eq. 90\n",
      "C:\\Users\\etmu9498\\AppData\\Local\\Temp\\ipykernel_24428\\1532473198.py:101: RuntimeWarning: invalid value encountered in log\n",
      "  Te = -1./np.log(lag1_r) # After Hartman 6.62 with delta t = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Heights = 72\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.20156\n",
      "Effective Sample Size Wilks N* (#independent samples): 48.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.2 and Te = 1.0\n",
      "Window = 60.0\n",
      "DOF = 2.4\n",
      "File: P3_20220925H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 89\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.72506\n",
      "Effective Sample Size Wilks N* (#independent samples): 14.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.72 and Te = 3.0\n",
      "Window = 74.16666666666667\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 76\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.74745\n",
      "Effective Sample Size Wilks N* (#independent samples): 11.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.75 and Te = 4.0\n",
      "Window = 63.333333333333336\n",
      "DOF = 2.4\n",
      "File: P3_20220926H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 33\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.44573\n",
      "Effective Sample Size Wilks N* (#independent samples): 13.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.43 and Te = 1.0\n",
      "Window = 27.5\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 33\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.43763\n",
      "Effective Sample Size Wilks N* (#independent samples): 13.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.44 and Te = 1.0\n",
      "Window = 27.5\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 25\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.71551\n",
      "Effective Sample Size Wilks N* (#independent samples): 4.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.69 and Te = 3.0\n",
      "Window = 20.833333333333336\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 3\n",
      "Number of Heights = 49\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.46682\n",
      "Effective Sample Size Wilks N* (#independent samples): 18.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.46 and Te = 1.0\n",
      "Window = 40.833333333333336\n",
      "DOF = 2.4\n",
      "File: P3_20220927H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 14\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.04608\n",
      "Effective Sample Size Wilks N* (#independent samples): 13.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.04 and Te = 0.0\n",
      "Window = 11.666666666666668\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 18\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.31503\n",
      "Effective Sample Size Wilks N* (#independent samples): 9.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.31 and Te = 1.0\n",
      "Window = 15.0\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 11\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.7098\n",
      "Effective Sample Size Wilks N* (#independent samples): 2.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.83 and Te = 5.0\n",
      "Window = 9.166666666666668\n",
      "DOF = 2.4\n",
      "File: P3_20221007H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 65\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.92548\n",
      "Effective Sample Size Wilks N* (#independent samples): 3.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.95 and Te = 20.0\n",
      "Window = 54.16666666666667\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 69\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.60191\n",
      "Effective Sample Size Wilks N* (#independent samples): 17.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.66 and Te = 2.0\n",
      "Window = 57.5\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 47\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.91191\n",
      "Effective Sample Size Wilks N* (#independent samples): 2.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.93 and Te = 13.0\n",
      "Window = 39.16666666666667\n",
      "DOF = 2.4\n",
      "File: P3_20221008H1_processed.nc\n",
      "\n",
      "Eye pass 0\n",
      "Number of Heights = 51\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.49936\n",
      "Effective Sample Size Wilks N* (#independent samples): 17.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.5 and Te = 1.0\n",
      "Window = 42.5\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 1\n",
      "Number of Heights = 52\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.42205\n",
      "Effective Sample Size Wilks N* (#independent samples): 21.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.43 and Te = 1.0\n",
      "Window = 43.333333333333336\n",
      "DOF = 2.4\n",
      "\n",
      "Eye pass 2\n",
      "Number of Heights = 37\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.79449\n",
      "Effective Sample Size Wilks N* (#independent samples): 4.0\n",
      "\n",
      "Method 2: using windows\n",
      "lag-1 autocorrelation = 0.8 and Te = 4.0\n",
      "Window = 30.833333333333336\n",
      "DOF = 2.4\n",
      "\n",
      "Total passes = 86\n",
      "Average autocorrelation = 0.7135779337701983\n",
      "Total n* from individual eye passes = 1454.0\n"
     ]
    }
   ],
   "source": [
    "# choose which data subset to look at (all, 2021, 2022, or a dictionary)\n",
    "tc = 'all'\n",
    "\n",
    "# save n* calculations here\n",
    "nstar_total = 0\n",
    "autocorrelation_sum = 0\n",
    "passcount = 0\n",
    "\n",
    "indict = {}\n",
    "indict['2021'] = ['P3_20210929H2_processed.nc'] # ['P3_20210929H2_processed.nc']\n",
    "# tc = indict\n",
    "\n",
    "eye_limits='default'\n",
    "crl_root_path = \"/Users/etmu9498/research/data/crl-all-data-processed/\"\n",
    "alpha = 0.95 ## set statistical significance level\n",
    "label = 'Cloud Heights'\n",
    "# create an x axis\n",
    "scaling = 260 / 1000\n",
    "if scaling == .26:\n",
    "    xlabel = \"Distance from start (km)\"\n",
    "    freqlabel = 'Frequency (km^-1)'\n",
    "    xlims, ylims = [.0001, .4], [0, .4] # [0, .01]\n",
    "elif scaling == 2:\n",
    "    xlabel = \"Time Since Start (s)\"\n",
    "    freqlabel = 'Frequency (Hz)'\n",
    "    xlims, ylims = [.0001, .2], [0, .4] # [0, .01]\n",
    "\n",
    "\n",
    "# use a helper fn to get the relevant years and files\n",
    "yearlist, filelist = helper_fns_winter2023.get_crl_datasets( tc=tc)\n",
    "\n",
    "# print out the number of files to be used\n",
    "filecount = 0\n",
    "for yeari in range( len( filelist)):\n",
    "    # count all the names in this year, and add to the count\n",
    "    filecount += len( filelist[ yeari])\n",
    "print(\"Number of data files to be used in analysis: \" + str( filecount))\n",
    "\n",
    "# load eyewall limits from helper function\n",
    "metadata = eyewall_metadata.all_metadata( eye_limits=eye_limits)\n",
    "\n",
    "# do this for all the datasets! years and filenames\n",
    "for yeari, yearval in enumerate( yearlist):\n",
    "    print( \"Year: \" + yearval)\n",
    "    for filei, fileval in enumerate( filelist[ yeari]):\n",
    "        print( \"File: \" + fileval)\n",
    "\n",
    "        # grab the limits for this case\n",
    "        # simplified filename\n",
    "        date = fileval[7:11]\n",
    "        eyewall_limits = eyewall_finder_helper( yearval, date, metadata)\n",
    "                    \n",
    "        # do this for each of the eyewall limit pairs! Can have multiple eyes per crl dataset\n",
    "        for eyei, eyeval in enumerate( eyewall_limits):\n",
    "            print(\"\\nEye pass \" + str(eyei))\n",
    "            \n",
    "            # load crl data\n",
    "            os.chdir( crl_root_path + yearval)\n",
    "            crl_data = xr.open_dataset( fileval)\n",
    "\n",
    "            if len( eyeval) > 0:\n",
    "                # find the corresponding indices to the time limits\n",
    "                ind0 = np.argmin( np.abs(crl_data.time.values - eyeval[0] ))\n",
    "                ind1 = np.argmin( np.abs(crl_data.time.values - eyeval[1] ))\n",
    "\n",
    "                # clip relevant fields down to the eyewall limits\n",
    "                H = crl_data.height\n",
    "                power = crl_data.P_ch1[ ind0 : ind1, :]\n",
    "                axis = crl_data.time[ ind0 : ind1]\n",
    "                p3_height = crl_data.p3_height[ ind0 : ind1]\n",
    "                # find cloud top heights for values within the specified eye distance range\n",
    "                if yearval == '2021':\n",
    "                    cutoff = -30\n",
    "                elif yearval == '2022':\n",
    "                    cutoff = -40\n",
    "                heights, time = find_cloud_tops.find_cloud_heights( H, power, axis, p3_height, cutoff_power = cutoff)\n",
    "\n",
    "                x_mean=np.mean( heights)\n",
    "                x_std=np.std( heights)\n",
    "                x_norm = ( heights - x_mean) / x_std\n",
    "                xN = len( x_norm)\n",
    "                xsigma = np.std( x_norm)  ## calculate the standard deviation\n",
    "                xmean = np.mean( x_norm)  ## calculate the mean\n",
    "                lag=1\n",
    "                x_norm_pandas = xr.DataArray( x_norm).to_pandas()\n",
    "                x_t1_m = x_norm_pandas.iloc[0 : -1 * lag] - xmean\n",
    "                x_t2_m = x_norm_pandas.iloc[ lag : ] - xmean\n",
    "                xAR1 = method1( x_t1_m, x_t2_m, xN, lag, xsigma)\n",
    "                Nstar_wilks= np.round(((1-xAR1)/(1+xAR1))*xN) ## Barnes Chapter 2 eq. 88\n",
    "                Nstar_leith= np.round((-0.5*np.log(xAR1))*xN) ## Barnes Chapter 2 eq. 90\n",
    "                xNstar = Nstar_wilks\n",
    "                        \n",
    "                ## Calculate the power spectrum of red noise with lag1_r to use for significance testing\n",
    "                # do this for non-smoothed data\n",
    "                data = heights.copy() # temp, wv\n",
    "                dists = np.arange(len(data)) * scaling\n",
    "                \n",
    "                ### step 1: calculate lag-1 autocorrelation (lag1_r, rho) and the associated p value (lag1_p)\n",
    "                lag1_r,lag1_p = stats.pearsonr(data[0:len(data)-1],data[1:len(data)])\n",
    "                ### step 2: Calculate e-folding time for a red-noise process with this lag-1 autocorrelation\n",
    "                Te = -1./np.log(lag1_r) # After Hartman 6.62 with delta t = 1\n",
    "\n",
    "                ## Calculate the power spectrum of red noise with lag1_r to use for significance testing\n",
    "                wtype = 'hamming'\n",
    "                filttype='butter'\n",
    "                normalize=True\n",
    "                window_length = len(heights) / 1.2 # 240 # settings\n",
    "                T2 = window_length / 2\n",
    "                freq_w = ( np.arange(0., T2 + 1.) / window_length ) / scaling \n",
    "\n",
    "                # filter the data\n",
    "                # specify the window length for filters\n",
    "                window = 25 ## (default 25) \n",
    "                cutoff = .05 ## (default 1./11.)\n",
    "                N = 3 ## order\n",
    "                frequency_cutoff=0.04\n",
    "                Wn = frequency_cutoff*2 ## scalar given the critical frequency (all higher frequencies are removed)\n",
    "                # b, a = signal.butter(N, Wn, btype='high')                    \n",
    "                # y2 = signal.filtfilt(b,a,heights)\n",
    "\n",
    "                # calculate degrees of freedom n* here!\n",
    "                dof_welch=len(data) / (window_length / 2)  ### Barnes Eq. 59, factor fw=1 here (based on HW 4 instructions)\n",
    "\n",
    "                \n",
    "                # note: I think that method 1 is the correct way to calculate n* here! The window shouldn't impact the \n",
    "                # degrees of freedom\n",
    "                print(\"Number of Heights = \" + str(len(heights)))\n",
    "                print('Method 1: normalized heights')\n",
    "                print(f'np.correlate AR1: {round(xAR1[0], 5)}')\n",
    "                print(f'Effective Sample Size Wilks N* (#independent samples): {Nstar_wilks[0]}')\n",
    "                nstar_total += Nstar_wilks[0]\n",
    "                passcount += 1\n",
    "                autocorrelation_sum += xAR1[0]\n",
    "            \n",
    "                print(\"\\nMethod 2: using windows\")\n",
    "                print('lag-1 autocorrelation =',round(lag1_r,2),'and Te =',round(Te,0))\n",
    "                print(\"Window = \" + str(window_length))\n",
    "                print('DOF =', dof_welch)\n",
    "\n",
    "print(\"\\nTotal passes = \" + str(passcount))\n",
    "print(\"Average autocorrelation = \" + str(autocorrelation_sum / passcount))\n",
    "print(\"Total n* from individual eye passes = \" + str(nstar_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76d8524d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data files to be used in analysis: 35\n",
      "Year: 2021\n",
      "File: P3_20210811H1_processed.nc\n",
      "File: P3_20210812H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20210812H2_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20210813H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20210816H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20210817H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20210818H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20210819H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20210820H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20210821H2_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20210827H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20210828H1_processed.nc\n",
      "heights found\n",
      "File: P3_20210829H1_processed.nc\n",
      "heights found\n",
      "File: P3_20210925H1_processed.nc\n",
      "File: P3_20210926H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20210927H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20210929H2_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "Year: 2022\n",
      "File: P3_20220830H1_processed.nc\n",
      "File: P3_20220831H1_processed.nc\n",
      "File: P3_20220901H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20220903H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20220904H1_processed.nc\n",
      "heights found\n",
      "File: P3_20220905H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20220906H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20220908H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20220916H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20220917H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20220918H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20220920H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20220924H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20220925H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20220926H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20220927H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20221007H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "File: P3_20221008H1_processed.nc\n",
      "heights found\n",
      "heights found\n",
      "heights found\n",
      "number of cloud height data points: (11997,)\n",
      "Method 1: normalized heights\n",
      "np.correlate AR1: 0.90117\n",
      "Effective Sample Size Wilks N* (#independent samples): 624.0\n"
     ]
    }
   ],
   "source": [
    "# test #2- find autocorrelation for all eye clouds combined\n",
    "\n",
    "# choose which data subset to look at (all, 2021, 2022, or a dictionary)\n",
    "tc = 'all'\n",
    "\n",
    "indict = {}\n",
    "indict['2021'] = ['P3_20210929H2_processed.nc'] # ['P3_20210929H2_processed.nc']\n",
    "# tc = indict\n",
    "\n",
    "eye_limits='default'\n",
    "crl_root_path = \"/Users/etmu9498/research/data/crl-all-data-processed/\"\n",
    "\n",
    "# recursively save dates, cloud heights, and power outputs to lists here!\n",
    "dates, passes, cloudheights, heightaxes, powers = [], [], [], [], []\n",
    "\n",
    "# use a helper fn to get the relevant years and files\n",
    "yearlist, filelist = helper_fns_winter2023.get_crl_datasets( tc=tc)\n",
    "\n",
    "# print out the number of files to be used\n",
    "filecount = 0\n",
    "for yeari in range( len( filelist)):\n",
    "    # count all the names in this year, and add to the count\n",
    "    filecount += len( filelist[ yeari])\n",
    "print(\"Number of data files to be used in analysis: \" + str( filecount))\n",
    "\n",
    "# load eyewall limits from helper function\n",
    "metadata = eyewall_metadata.all_metadata( eye_limits=eye_limits)\n",
    "\n",
    "# do this for all the datasets! years and filenames\n",
    "for yeari, yearval in enumerate( yearlist):\n",
    "    print( \"Year: \" + yearval)\n",
    "    for filei, fileval in enumerate( filelist[ yeari]):\n",
    "        print( \"File: \" + fileval)\n",
    "\n",
    "        # grab the limits for this case\n",
    "        # simplified filename\n",
    "        date = fileval[7:11]\n",
    "        # check if this date exists... if not, give it some empty eyewall limits!\n",
    "        # also account for fred am and pm cases!!\n",
    "        if date == '0812':\n",
    "            if fileval[11:13] == \"H1\":\n",
    "                eyewall_limits = metadata[ yearval]['eyewall_limits'][ '0812am']\n",
    "            elif fileval[11:13] == \"H2\":\n",
    "                eyewall_limits = metadata[ yearval]['eyewall_limits'][ '0812pm']\n",
    "        elif date in metadata[ yearval]['eyewall_limits'].keys():\n",
    "            eyewall_limits = metadata[ yearval]['eyewall_limits'][ date]\n",
    "        else:\n",
    "            eyewall_limits = [ ()]\n",
    "            \n",
    "            \n",
    "        # do this for each of the eyewall limit pairs! Can have multiple eyes per crl dataset\n",
    "        for eyei, eyeval in enumerate( eyewall_limits):\n",
    "            # load crl data\n",
    "            os.chdir( crl_root_path + yearval)\n",
    "            crl_data = xr.open_dataset( fileval)\n",
    "\n",
    "            if len( eyeval) > 0:\n",
    "\n",
    "                # find the corresponding indices to the time limits\n",
    "                ind0 = np.argmin( np.abs(crl_data.time.values - eyeval[0] ))\n",
    "                ind1 = np.argmin( np.abs(crl_data.time.values - eyeval[1] ))\n",
    "\n",
    "                # clip relevant fields down to the eyewall limits\n",
    "                H = crl_data.height\n",
    "                power = crl_data.P_ch1[ ind0 : ind1, :]\n",
    "                axis = crl_data.time[ ind0 : ind1]\n",
    "                p3_height = crl_data.p3_height[ ind0 : ind1]\n",
    "\n",
    "                #print( \"h: \" + str( len( H)))\n",
    "                #print( \"power: \" + str( np.shape( power)))\n",
    "                #print( 't: ' + str( len( axis)))\n",
    "\n",
    "                # find cloud top heights for values within the specified eye distance range\n",
    "                if yearval == '2021':\n",
    "                    cutoff = -30\n",
    "                elif yearval == '2022':\n",
    "                    cutoff = -40\n",
    "                heights, time = find_cloud_tops.find_cloud_heights( H, power, axis, p3_height, cutoff_power = cutoff)\n",
    "                \n",
    "                cloudheights.append(heights)\n",
    "                dates.append(date)\n",
    "                passes.append(eyei)\n",
    "                powers.append(power)\n",
    "                heightaxes.append(H.values)\n",
    "                \n",
    "                print(\"heights found\")\n",
    "\n",
    "# concatenate and plot all cloud heights together!\n",
    "allheights = np.array([])\n",
    "for chi, chval in enumerate(cloudheights):\n",
    "    allheights = np.concatenate( (allheights, chval), axis=0)\n",
    "print('number of cloud height data points: ' + str(np.shape(allheights)))\n",
    "\n",
    "# standardize the data and find the autocorrelation!\n",
    "x_mean=np.mean( allheights)\n",
    "x_std=np.std( allheights)\n",
    "x_norm = ( allheights - x_mean) / x_std\n",
    "xN = len( x_norm)\n",
    "xsigma = np.std( x_norm)  ## calculate the standard deviation\n",
    "xmean = np.mean( x_norm)  ## calculate the mean\n",
    "lag=1\n",
    "x_norm_pandas = xr.DataArray( x_norm).to_pandas()\n",
    "x_t1_m = x_norm_pandas.iloc[0 : -1 * lag] - xmean\n",
    "x_t2_m = x_norm_pandas.iloc[ lag : ] - xmean\n",
    "xAR1 = method1( x_t1_m, x_t2_m, xN, lag, xsigma)\n",
    "Nstar_wilks= np.round(((1-xAR1)/(1+xAR1))*xN) ## Barnes Chapter 2 eq. 88\n",
    "Nstar_leith= np.round((-0.5*np.log(xAR1))*xN) ## Barnes Chapter 2 eq. 90\n",
    "xNstar = Nstar_wilks\n",
    "\n",
    "print('Method 1: normalized heights')\n",
    "print(f'np.correlate AR1: {round(xAR1[0], 5)}')\n",
    "print(f'Effective Sample Size Wilks N* (#independent samples): {Nstar_wilks[0]}')\n",
    "nstar_total += Nstar_wilks[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703cd5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
